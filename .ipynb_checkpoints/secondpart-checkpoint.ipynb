{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - Evaluation of COMPAS dataset\n",
    "\n",
    "#### Group Members : \n",
    "                Marck-Edward KEMEH - marck-edward.kemeh@grenoble-inp.org\n",
    "                Irman FAQRIZAL - irman.faqrizal@univ-grenoble-alpes.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import urllib\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from pylab import rcParams\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_extraction, preprocessing\n",
    "from random import seed, shuffle\n",
    "#from __future__ import division\n",
    "#from collections import defaultdict\n",
    "#import utils as ut\n",
    "\n",
    "#function to plot grid\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "df = pd.read_csv('compas-scores-two-years.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex          age_cat              race  juv_fel_count  juv_misd_count  \\\n",
       "0  Male  Greater than 45             Other              0               0   \n",
       "1  Male          25 - 45  African-American              0               0   \n",
       "2  Male     Less than 25  African-American              0               0   \n",
       "3  Male     Less than 25  African-American              0               1   \n",
       "4  Male          25 - 45             Other              0               0   \n",
       "\n",
       "   priors_count c_charge_degree  is_violent_recid  v_decile_score  event  \\\n",
       "0             0               F                 0               1      0   \n",
       "1             0               F                 1               1      1   \n",
       "2             4               F                 0               3      0   \n",
       "3             1               F                 0               6      0   \n",
       "4             2               F                 0               1      0   \n",
       "\n",
       "   two_year_recid  \n",
       "0               0  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing data by selecting needed colums and removing empty values\n",
    "df = df[df.columns[~df.isnull().any()]]\n",
    "df = df[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', 'two_year_recid']]\n",
    "#df = df.dropna(how='any')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we need to convert string data into values/ numbers to be able to use it to train, test and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age_cat  race  juv_fel_count  juv_misd_count  priors_count  \\\n",
       "0    1        1     1              0               0             0   \n",
       "1    1        2     2              0               0             0   \n",
       "2    1        3     2              0               0             4   \n",
       "3    1        3     2              0               1             1   \n",
       "4    1        2     1              0               0             2   \n",
       "\n",
       "   c_charge_degree  is_violent_recid  v_decile_score  event  two_year_recid  \n",
       "0                1                 0               1      0               0  \n",
       "1                1                 1               1      1               1  \n",
       "2                1                 0               3      0               1  \n",
       "3                1                 0               6      0               0  \n",
       "4                1                 0               1      0               0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting to values\n",
    "df['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### splitting dataset and choosing ground truth\n",
    "\n",
    "Next step is to divide our dataset. we cannot use the same data trained for testing so we divide the data into train and test set. we will use 0.2 percent of the training dataset as the validation set. We then need to convert them into a tensor(a set of data/ information relating to one person as relating to COMPAS) to be able to train and test with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5771, 10]) torch.Size([5771])\n",
      "torch.Size([1443, 10]) torch.Size([1443])\n"
     ]
    }
   ],
   "source": [
    "#splitting and converting data to tensor\n",
    "X = df[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event']]\n",
    "y = df[['two_year_recid']] #ground truth\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# X_train.astype(dtype = 'float32')\n",
    "X_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
    "X_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the network\n",
    "From the shape above, our input data contains 10 columns which also means our input feature is 10. Network input also has to match up to this number.\n",
    "Our network will also have two hidden layers of 5 and 3 nodes respectively\n",
    "\n",
    "#### First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 5)\n",
    "    self.fc2 = nn.Linear(5, 3)\n",
    "    self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "net = Net(X_train.shape[1])\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train set - loss: 0.68, accuracy: 0.625\n",
      "Test  set - loss: 0.677, accuracy: 0.647\n",
      "\n",
      "epoch 400\n",
      "Train set - loss: 0.423, accuracy: 0.886\n",
      "Test  set - loss: 0.418, accuracy: 0.891\n",
      "\n",
      "epoch 800\n",
      "Train set - loss: 0.333, accuracy: 0.907\n",
      "Test  set - loss: 0.332, accuracy: 0.911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ann_viz(net, view=False)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# X_train = X_train.to(device)\n",
    "# y_train = y_train.to(device)\n",
    "# X_test = X_test.to(device)\n",
    "# y_test = y_test.to(device)\n",
    "# net = net.to(device)\n",
    "# criterion = criterion.to(device)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)\n",
    "\n",
    "for epoch in range(1200):\n",
    "    \n",
    "    y_pred = net(X_train)\n",
    "    \n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "\n",
    "      y_test_pred = net(X_test)\n",
    "      y_test_pred = torch.squeeze(y_test_pred)\n",
    "\n",
    "      test_loss = criterion(y_test_pred, y_test)\n",
    "\n",
    "      test_acc = calculate_accuracy(y_test, y_test_pred)\n",
    "      print(\n",
    "f'''epoch {epoch}\n",
    "Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n",
    "''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    train_loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "# Save model\n",
    "MODEL_PATH = 'model.pth'\n",
    "torch.save(net, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.89      0.96      0.93       823\n",
      "       Recid       0.94      0.85      0.89       620\n",
      "\n",
      "    accuracy                           0.91      1443\n",
      "   macro avg       0.92      0.90      0.91      1443\n",
      "weighted avg       0.91      0.91      0.91      1443\n",
      "\n",
      "Overall Accuracy :  0.9126819126819127\n"
     ]
    }
   ],
   "source": [
    "# Test the model using test set\n",
    "net = torch.load(MODEL_PATH)\n",
    "classes = ['No Recid', 'Recid']\n",
    "y_pred = net(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model produces a higher overall accuracy of 0.91 as compared to the compass model of 0.65 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Recidivism(tendency to reoffend) based on first model\n",
    "Definitions and possible parameters.\n",
    "We would like to analyse some possible attributes that account for the risk of recidivism. Prior_count, race and decile scores.\n",
    "\n",
    "some sample Predictions follow below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex : [1 2]\n",
      "race : [1 2 3 4 5 6]\n",
      "age_cat : [1 2 3]\n",
      "juv_fel_count : [ 0  2  1  8  4  3  9 20  6  5 10]\n",
      "juv_misd_count : [ 0  1  6 12  2  4  3  8  5 13]\n",
      "priors_count : [ 0  4  1  2 14  3  7  6  5 13  8  9 21 20 15 10 12 28 19 11 22 23 25 24\n",
      " 36 18 16 33 17 30 27 38 26 37 29 35 31]\n",
      "c_charge_degree : [1 2]\n",
      "is_violent_recid : [0 1]\n",
      "v_decile_score : [ 1  3  6  2  5  4  9  7 10  8]\n",
      "event : [0 1]\n"
     ]
    }
   ],
   "source": [
    "def will_recid(sex,age_cat, race, juv_fel_count, juv_misd_count, priors_count, c_charge_degree, is_violent_recid, v_decile_score, event):\n",
    "  t = torch.as_tensor([sex,age_cat, race, juv_fel_count, juv_misd_count, priors_count, c_charge_degree, is_violent_recid, v_decile_score, event]) \\\n",
    "      .float()\n",
    "  output = net(t)\n",
    "  return output.ge(0.5).item()\n",
    "\n",
    "# Possible values\n",
    "print(\"sex : \" + str(df.sex.unique()))\n",
    "print(\"race : \" + str(df.race.unique()))\n",
    "print(\"age_cat : \" + str(df.age_cat.unique()))\n",
    "print(\"juv_fel_count : \" + str(df.juv_fel_count.unique()))\n",
    "print(\"juv_misd_count : \" + str(df.juv_misd_count.unique()))\n",
    "print(\"priors_count : \" + str(df.priors_count.unique()))\n",
    "print(\"c_charge_degree : \" + str(df.c_charge_degree.unique()))\n",
    "print(\"is_violent_recid : \" + str(df.is_violent_recid.unique()))\n",
    "print(\"v_decile_score : \" + str(df.v_decile_score.unique()))\n",
    "print(\"event : \" + str(df.event.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We want to determine if our model work like Propublica (same, better or worse) by predicting few instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=1, race= 2, age_cat=1, juv_fel_count=2, juv_misd_count=6, priors_count =14, \n",
    "           c_charge_degree =1, is_violent_recid =1, v_decile_score =1, event= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=2, race= 5, age_cat=3, juv_fel_count=1, juv_misd_count=0, priors_count =1, \n",
    "           c_charge_degree =7, is_violent_recid =0, v_decile_score =3, event= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=1, race= 2, age_cat=1, juv_fel_count=0, juv_misd_count=1, priors_count =0, \n",
    "           c_charge_degree =1, is_violent_recid =0, v_decile_score =1, event= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=1, race= 2, age_cat=1, juv_fel_count=2, juv_misd_count=0, priors_count =0, c_charge_degree =1, \n",
    "           is_violent_recid =0, v_decile_score =4, event= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=1, race= 5, age_cat=2, juv_fel_count=0, juv_misd_count=2, priors_count =2, c_charge_degree =0, \n",
    "           is_violent_recid =1, v_decile_score =3, event= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Model\n",
    "For subsequent model, we would like to used a validation set. From the dataset, we use 20% of it as the test set and he rest is used for training. We then use 10% of the training set for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>Notes\n",
    "<li>two_year_recid is not possibility. Its the ground truth. What we are trying to do there is to show the ground truth is relatively balanced</li>\n",
    "<li>we could split two times the data, until we have separate: training, testing, and validation set.</li>\n",
    "<li>Maybe its okay to show the figure of the architecture.\n",
    "<li>What is the v_decile_graph for?</li>\n",
    "<li>We can compare by making predictions of some rows in the dataset where the compas classifier failed. For intance maybe there are some rows where score_text is 'High' and decile_score is '10' however the criminals didn't recid (two_year_recid = 0)</li>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\t :torch.Size([5193, 10]), torch.Size([5193])\n",
      "Testing\t\t :torch.Size([1443, 10]), torch.Size([1443])\n",
      "Validation\t :torch.Size([578, 10]), torch.Size([578])\n"
     ]
    }
   ],
   "source": [
    "# Arrange the data : Training, Testing, Validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.1, random_state=RANDOM_SEED)\n",
    "\n",
    "# conversion to tensor\n",
    "X_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
    "X_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
    "X_validate = torch.from_numpy(X_validate.to_numpy()).float()\n",
    "y_validate = torch.squeeze(torch.from_numpy(y_validate.to_numpy()).float())\n",
    "\n",
    "print(\"Training\\t :\"+ str(X_train.shape) +\", \"+ str(y_train.shape))\n",
    "print(\"Testing\\t\\t :\"+ str(X_test.shape) +\", \"+ str(y_test.shape))\n",
    "print(\"Validation\\t :\"+ str(X_validate.shape) +\", \"+ str(y_validate.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Mean Squared Error(MSE)\n",
    "MSE is the default loss function to be used in a regression problem. this is also used when the data is not seperable or for estimation purposes.\n",
    "obviously, this will not perform well on this classification but none the less, we want to see why and how it performs on classification problems.\n",
    "MSE measures the average squared difference between the estimated values and the actual values.\n",
    "With MSE, it is a requirement that the output layer has just one node and also he linear activation function is used in this respect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=5, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "epoch 0\n",
      "            Train set\t\t - loss: 3782.121, accuracy: 0.544\n",
      "            Validation set\t - loss: 410.482, accuracy: 0.547\n",
      "            \n",
      "epoch 400\n",
      "            Train set\t\t - loss: 3782.121, accuracy: 0.544\n",
      "            Validation set\t - loss: 410.482, accuracy: 0.547\n",
      "            \n",
      "epoch 800\n",
      "            Train set\t\t - loss: 3782.121, accuracy: 0.544\n",
      "            Validation set\t - loss: 410.482, accuracy: 0.547\n",
      "            \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.57      1.00      0.73       823\n",
      "       Recid       0.00      0.00      0.00       620\n",
      "\n",
      "    accuracy                           0.57      1443\n",
      "   macro avg       0.29      0.50      0.36      1443\n",
      "weighted avg       0.33      0.57      0.41      1443\n",
      "\n",
      "Overall Accuracy :  0.5703395703395704\n"
     ]
    }
   ],
   "source": [
    "#try using different loss function #2\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "#using a nn module from pytorch\n",
    "secondmodel = nn.Sequential(\n",
    "    nn.Linear(10, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "#     nn.Sigmoid()\n",
    ")\n",
    "print(secondmodel)\n",
    "print(\"\\n\")\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "for epoch in range(1200):\n",
    "    y_pred = secondmodel(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_validate_pred = secondmodel(X_validate)\n",
    "      y_validate_pred = torch.squeeze(y_validate_pred)\n",
    "      validate_loss = criterion(y_validate_pred, y_validate)\n",
    "      validation_acc = calculate_accuracy(y_validate, y_validate_pred)\n",
    "      print(\n",
    "            f'''epoch {epoch}\n",
    "            Train set\\t\\t - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "            Validation set\\t - loss: {round_tensor(validate_loss)}, accuracy: {round_tensor(validation_acc)}\n",
    "            ''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the model using test set\n",
    "y_pred = secondmodel(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model performed poorly using MSE as the loss function. overall accuracy is at 0.64 which is not good to use for predicting if a criminal will recidiviate or not. The accuracy is almost the same as the compass accuacy standing at 0.653.\n",
    "\n",
    "#### Third Model\n",
    "for this model, we would want to see the performance when using tanh activation functions which is non linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thirdmodel(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "epoch 0\n",
      "            Train set\t\t - loss: 1348.973, accuracy: 0.544\n",
      "            Validation set\t - loss: 148.673, accuracy: 0.547\n",
      "            \n",
      "epoch 400\n",
      "            Train set\t\t - loss: 572.736, accuracy: 0.906\n",
      "            Validation set\t - loss: 67.749, accuracy: 0.894\n",
      "            \n",
      "epoch 800\n",
      "            Train set\t\t - loss: 397.545, accuracy: 0.909\n",
      "            Validation set\t - loss: 48.608, accuracy: 0.9\n",
      "            \n",
      "epoch 1200\n",
      "            Train set\t\t - loss: 384.607, accuracy: 0.909\n",
      "            Validation set\t - loss: 46.882, accuracy: 0.903\n",
      "            \n",
      "epoch 1600\n",
      "            Train set\t\t - loss: 380.594, accuracy: 0.91\n",
      "            Validation set\t - loss: 46.471, accuracy: 0.903\n",
      "            \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.90      0.96      0.93       823\n",
      "       Recid       0.94      0.85      0.90       620\n",
      "\n",
      "    accuracy                           0.91      1443\n",
      "   macro avg       0.92      0.91      0.91      1443\n",
      "weighted avg       0.92      0.91      0.91      1443\n",
      "\n",
      "Overall Accuracy :  0.9147609147609148\n"
     ]
    }
   ],
   "source": [
    "# Using different activation functions : from relu -> tanh\n",
    "class thirdmodel(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features):\n",
    "    super(thirdmodel, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 5)\n",
    "    self.fc2 = nn.Linear(5, 3)\n",
    "    self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.tanh(self.fc1(x))\n",
    "    x = F.tanh(self.fc2(x))\n",
    "    return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "net = thirdmodel(X_train.shape[1])\n",
    "print(net)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "print(\"\\n\")\n",
    "for epoch in range(2000):\n",
    "    y_pred = net(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_validate_pred = net(X_validate)\n",
    "      y_validate_pred = torch.squeeze(y_validate_pred)\n",
    "      validate_loss = criterion(y_validate_pred, y_validate)\n",
    "      validation_acc = calculate_accuracy(y_validate, y_validate_pred)\n",
    "      print(\n",
    "            f'''epoch {epoch}\n",
    "            Train set\\t\\t - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "            Validation set\\t - loss: {round_tensor(validate_loss)}, accuracy: {round_tensor(validation_acc)}\n",
    "            ''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the model using test set\n",
    "y_pred = net(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our third model performs almost same as our first model which had an accuracy of 0.912 and obviously better than the accuracy of compas.\n",
    "### fourth model\n",
    "we build a fourth model by adding more layers to model 2 and more neurons to the hidden layers. Neurons on the input layers has to remain same to fit the shape of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourthmodel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "epoch 0\n",
      "            Train set\t\t - loss: 1329.712, accuracy: 0.456\n",
      "            Validation set\t - loss: 148.17, accuracy: 0.453\n",
      "            \n",
      "epoch 400\n",
      "            Train set\t\t - loss: 371.416, accuracy: 0.914\n",
      "            Validation set\t - loss: 45.39, accuracy: 0.903\n",
      "            \n",
      "epoch 800\n",
      "            Train set\t\t - loss: 356.772, accuracy: 0.92\n",
      "            Validation set\t - loss: 46.42, accuracy: 0.901\n",
      "            \n",
      "epoch 1200\n",
      "            Train set\t\t - loss: 346.367, accuracy: 0.924\n",
      "            Validation set\t - loss: 48.168, accuracy: 0.896\n",
      "            \n",
      "epoch 1600\n",
      "            Train set\t\t - loss: 338.929, accuracy: 0.925\n",
      "            Validation set\t - loss: 47.637, accuracy: 0.9\n",
      "            \n",
      "epoch 2000\n",
      "            Train set\t\t - loss: 333.493, accuracy: 0.927\n",
      "            Validation set\t - loss: 48.037, accuracy: 0.903\n",
      "            \n",
      "epoch 2400\n",
      "            Train set\t\t - loss: 328.108, accuracy: 0.93\n",
      "            Validation set\t - loss: 48.672, accuracy: 0.9\n",
      "            \n",
      "epoch 2800\n",
      "            Train set\t\t - loss: 323.202, accuracy: 0.931\n",
      "            Validation set\t - loss: 49.195, accuracy: 0.898\n",
      "            \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.90      0.93      0.91       823\n",
      "       Recid       0.91      0.86      0.88       620\n",
      "\n",
      "    accuracy                           0.90      1443\n",
      "   macro avg       0.90      0.90      0.90      1443\n",
      "weighted avg       0.90      0.90      0.90      1443\n",
      "\n",
      "Overall Accuracy :  0.9009009009009009\n"
     ]
    }
   ],
   "source": [
    "# Defining the model  #4\n",
    "# Adding layers and neurons\n",
    "class fourthmodel(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features):\n",
    "    super(fourthmodel, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 20)\n",
    "    self.fc2 = nn.Linear(20, 20)\n",
    "    self.fc3 = nn.Linear(20, 10)\n",
    "    self.fc4 = nn.Linear(10, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.tanh(self.fc1(x))\n",
    "    x = F.tanh(self.fc2(x))\n",
    "    x = F.tanh(self.fc3(x))\n",
    "    return torch.sigmoid(self.fc4(x))\n",
    "\n",
    "net = fourthmodel(X_train.shape[1])\n",
    "print(net)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "print(\"\\n\")\n",
    "for epoch in range(3200):\n",
    "    y_pred = net(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_validate_pred = net(X_validate)\n",
    "      y_validate_pred = torch.squeeze(y_validate_pred)\n",
    "      validate_loss = criterion(y_validate_pred, y_validate)\n",
    "      validation_acc = calculate_accuracy(y_validate, y_validate_pred)\n",
    "      print(\n",
    "            f'''epoch {epoch}\n",
    "            Train set\\t\\t - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "            Validation set\\t - loss: {round_tensor(validate_loss)}, accuracy: {round_tensor(validation_acc)}\n",
    "            ''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the model using test set\n",
    "y_pred = net(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that the accuracy reduced a little by 0.012 as compared to the original third model. We can say that trying to increase the accuracy of the classifier does not have to do with only adding more layers and neurons to the network. We can also observe overfitting starting at epoch 2400.\n",
    "### Fifth model\n",
    "still use the second model but with relu as the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fifthmodel(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "epoch 0\n",
      "            Train set\t\t - loss: 1302.5, accuracy: 0.533\n",
      "            Validation set\t - loss: 144.91, accuracy: 0.528\n",
      "            \n",
      "epoch 400\n",
      "            Train set\t\t - loss: 450.755, accuracy: 0.909\n",
      "            Validation set\t - loss: 54.167, accuracy: 0.9\n",
      "            \n",
      "epoch 800\n",
      "            Train set\t\t - loss: 388.699, accuracy: 0.909\n",
      "            Validation set\t - loss: 47.726, accuracy: 0.9\n",
      "            \n",
      "epoch 1200\n",
      "            Train set\t\t - loss: 387.76, accuracy: 0.908\n",
      "            Validation set\t - loss: 47.619, accuracy: 0.901\n",
      "            \n",
      "epoch 1600\n",
      "            Train set\t\t - loss: 387.53, accuracy: 0.908\n",
      "            Validation set\t - loss: 47.59, accuracy: 0.901\n",
      "            \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.89      0.96      0.93       823\n",
      "       Recid       0.95      0.85      0.89       620\n",
      "\n",
      "    accuracy                           0.91      1443\n",
      "   macro avg       0.92      0.91      0.91      1443\n",
      "weighted avg       0.92      0.91      0.91      1443\n",
      "\n",
      "Overall Accuracy :  0.9133749133749134\n"
     ]
    }
   ],
   "source": [
    "# Defining the model #5\n",
    "# Using custom module\n",
    "class fifthmodel(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features):\n",
    "    super(fifthmodel, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 5)\n",
    "    self.fc2 = nn.Linear(5, 3)\n",
    "    self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "net = fifthmodel(X_train.shape[1])\n",
    "print(net)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "print(\"\\n\")\n",
    "for epoch in range(2000):\n",
    "    y_pred = net(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_validate_pred = net(X_validate)\n",
    "      y_validate_pred = torch.squeeze(y_validate_pred)\n",
    "      validate_loss = criterion(y_validate_pred, y_validate)\n",
    "      validation_acc = calculate_accuracy(y_validate, y_validate_pred)\n",
    "      print(\n",
    "            f'''epoch {epoch}\n",
    "            Train set\\t\\t - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "            Validation set\\t - loss: {round_tensor(validate_loss)}, accuracy: {round_tensor(validation_acc)}\n",
    "            ''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the model using test set\n",
    "y_pred = net(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### note - add graph of accuracy.\n",
    "an overall accuracy of 0.913 almost same as using tanh as the activation function.\n",
    "\n",
    "#### Predictions based on fifthmodel\n",
    "\n",
    "we want to define a new dataset to use for prediction and oserve fairness. We will use criminals labelled with the various risk score/decile score but having a two_year_recid or for this analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data is  (402, 10)\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True,  True, False, False, False, False, False,\n",
      "        False, False,  True, False,  True, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False, False, False, False, False, False,  True,  True, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False,  True, False, False,\n",
      "        False, False, False,  True,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False,  True,  True, False, False, False, False,  True, False, False,\n",
      "        False,  True,  True, False, False, False, False, False,  True,  True,\n",
      "         True,  True, False, False, False, False, False, False,  True, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False, False,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "         True, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False,  True, False, False, False, False,  True,  True, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False,  True,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "        False,  True, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-8ba2a17814f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mX_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#no two_year _recid with high label\n",
    "df2 = df2.loc[(df2['two_year_recid']==0) & (df2['score_text']=='High')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of data is ', df2.shape)\n",
    "\n",
    "#prediction\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of is  (2681, 10)\n",
      "tensor([False, False, False,  ..., False, False, False])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#no two_year _recid with Low label\n",
    "df2 = df2.loc[(df2['two_year_recid']==0) & (df2['score_text']=='Low')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of is ', df2.shape)\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of is  (1216, 10)\n",
      "tensor([ True, False,  True,  ...,  True,  True, False])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#two_year _recid with Low label\n",
    "df2 = df2.loc[(df2['two_year_recid']==1) & (df2['score_text']=='Low')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of is ', df2.shape)\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of is  (1001, 10)\n",
      "tensor([True, True, True,  ..., True, True, True])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#two_year _recid with high label\n",
    "df2 = df2.loc[(df2['two_year_recid']==1) & (df2['score_text']=='High')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of is ', df2.shape)\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of is  (880, 10)\n",
      "tensor([ True, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "         True, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "         True,  True, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "         True, False, False,  True, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False,  True,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False, False, False,\n",
      "         True, False, False, False,  True, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False,  True, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False,  True,  True, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False,  True, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False,  True,  True, False,  True, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#no two_year _recid with Medium label\n",
    "df2 = df2.loc[(df2['two_year_recid']==0) & (df2['score_text']=='Medium')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of is ', df2.shape)\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of is  (402, 10)\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True,  True, False, False, False, False, False,\n",
      "        False, False,  True, False,  True, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False, False, False, False, False, False,  True,  True, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False,  True, False, False,\n",
      "        False, False, False,  True,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False,  True,  True, False, False, False, False,  True, False, False,\n",
      "        False,  True,  True, False, False, False, False, False,  True,  True,\n",
      "         True,  True, False, False, False, False, False, False,  True, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False, False,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "         True, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False,  True, False, False, False, False,  True,  True, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False,  True,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "        False,  True, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#no two_year _recid with high label\n",
    "df2 = df2.loc[(df2['two_year_recid']==0) & (df2['score_text']=='High')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of is ', df2.shape)\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
