{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - Evaluation of COMPAS dataset\n",
    "\n",
    "#### Group Members : \n",
    "                Marck-Edward KEMEH - marck-edward.kemeh@grenoble-inp.org\n",
    "                Irman FAQRIZAL - irman.faqrizal@univ-grenoble-alpes.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import urllib\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from pylab import rcParams\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_extraction, preprocessing\n",
    "from random import seed, shuffle\n",
    "#from __future__ import division\n",
    "#from collections import defaultdict\n",
    "#import utils as ut\n",
    "\n",
    "#function to plot grid\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "df = pd.read_csv('compas-scores-two-years.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex          age_cat              race  juv_fel_count  juv_misd_count  \\\n",
       "0  Male  Greater than 45             Other              0               0   \n",
       "1  Male          25 - 45  African-American              0               0   \n",
       "2  Male     Less than 25  African-American              0               0   \n",
       "3  Male     Less than 25  African-American              0               1   \n",
       "4  Male          25 - 45             Other              0               0   \n",
       "\n",
       "   priors_count c_charge_degree  is_violent_recid  v_decile_score  event  \\\n",
       "0             0               F                 0               1      0   \n",
       "1             0               F                 1               1      1   \n",
       "2             4               F                 0               3      0   \n",
       "3             1               F                 0               6      0   \n",
       "4             2               F                 0               1      0   \n",
       "\n",
       "   two_year_recid  \n",
       "0               0  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing data by selecting needed colums and removing empty values\n",
    "df = df[df.columns[~df.isnull().any()]]\n",
    "df = df[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', 'two_year_recid']]\n",
    "#df = df.dropna(how='any')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we need to convert string data into values/ numbers to be able to use it to train, test and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age_cat  race  juv_fel_count  juv_misd_count  priors_count  \\\n",
       "0    1        1     1              0               0             0   \n",
       "1    1        2     2              0               0             0   \n",
       "2    1        3     2              0               0             4   \n",
       "3    1        3     2              0               1             1   \n",
       "4    1        2     1              0               0             2   \n",
       "\n",
       "   c_charge_degree  is_violent_recid  v_decile_score  event  two_year_recid  \n",
       "0                1                 0               1      0               0  \n",
       "1                1                 1               1      1               1  \n",
       "2                1                 0               3      0               1  \n",
       "3                1                 0               6      0               0  \n",
       "4                1                 0               1      0               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting to values\n",
    "df['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### splitting dataset and choosing ground truth\n",
    "\n",
    "Next step is to divide our dataset. we cannot use the same data trained for testing so we divide the data into train and test set. we will use 0.2 percent of the training dataset as the validation set. We then need to convert them into a tensor(a set of data/ information relating to one person as relating to COMPAS) to be able to train and test with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5771, 10]) torch.Size([5771])\n",
      "torch.Size([1443, 10]) torch.Size([1443])\n"
     ]
    }
   ],
   "source": [
    "#splitting and converting data to tensor\n",
    "X = df[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event']]\n",
    "y = df[['two_year_recid']] #ground truth\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# X_train.astype(dtype = 'float32')\n",
    "X_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
    "X_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the network\n",
    "From the shape above, our input data contains 10 columns which also means our input feature is 10. Network input also has to match up to this number.\n",
    "Our network will also have two hidden layers of 5 and 3 nodes respectively\n",
    "\n",
    "#### First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 5)\n",
    "    self.fc2 = nn.Linear(5, 3)\n",
    "    self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "net = Net(X_train.shape[1])\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Train set - loss: 0.704, accuracy: 0.544\n",
      "Test  set - loss: 0.7, accuracy: 0.57\n",
      "\n",
      "epoch 400\n",
      "Train set - loss: 0.307, accuracy: 0.907\n",
      "Test  set - loss: 0.298, accuracy: 0.911\n",
      "\n",
      "epoch 800\n",
      "Train set - loss: 0.272, accuracy: 0.907\n",
      "Test  set - loss: 0.26, accuracy: 0.912\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marck-edward/miniconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# ann_viz(net, view=False)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# X_train = X_train.to(device)\n",
    "# y_train = y_train.to(device)\n",
    "# X_test = X_test.to(device)\n",
    "# y_test = y_test.to(device)\n",
    "# net = net.to(device)\n",
    "# criterion = criterion.to(device)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)\n",
    "\n",
    "for epoch in range(1200):\n",
    "    \n",
    "    y_pred = net(X_train)\n",
    "    \n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "\n",
    "      y_test_pred = net(X_test)\n",
    "      y_test_pred = torch.squeeze(y_test_pred)\n",
    "\n",
    "      test_loss = criterion(y_test_pred, y_test)\n",
    "\n",
    "      test_acc = calculate_accuracy(y_test, y_test_pred)\n",
    "      print(\n",
    "f'''epoch {epoch}\n",
    "Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n",
    "''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    train_loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "# Save model\n",
    "MODEL_PATH = 'model.pth'\n",
    "torch.save(net, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.89      0.96      0.93       823\n",
      "       Recid       0.94      0.85      0.89       620\n",
      "\n",
      "    accuracy                           0.91      1443\n",
      "   macro avg       0.92      0.90      0.91      1443\n",
      "weighted avg       0.91      0.91      0.91      1443\n",
      "\n",
      "Overall Accuracy :  0.911988911988912\n"
     ]
    }
   ],
   "source": [
    "# Test the model using test set\n",
    "net = torch.load(MODEL_PATH)\n",
    "classes = ['No Recid', 'Recid']\n",
    "y_pred = net(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model produces a higher overall accuracy of 0.91 as compared to the compass model of 0.65 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Recidivism(tendency to reoffend) based on first model\n",
    "Definitions and possible parameters.\n",
    "We would like to analyse some possible attributes that account for the risk of recidivism. Prior_count, race and decile scores.\n",
    "\n",
    "some sample Predictions follow below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex : [1 2]\n",
      "race : [1 2 3 4 5 6]\n",
      "age_cat : [1 2 3]\n",
      "juv_fel_count : [ 0  2  1  8  4  3  9 20  6  5 10]\n",
      "juv_misd_count : [ 0  1  6 12  2  4  3  8  5 13]\n",
      "priors_count : [ 0  4  1  2 14  3  7  6  5 13  8  9 21 20 15 10 12 28 19 11 22 23 25 24\n",
      " 36 18 16 33 17 30 27 38 26 37 29 35 31]\n",
      "c_charge_degree : [1 2]\n",
      "is_violent_recid : [0 1]\n",
      "v_decile_score : [ 1  3  6  2  5  4  9  7 10  8]\n",
      "event : [0 1]\n"
     ]
    }
   ],
   "source": [
    "def will_recid(sex,age_cat, race, juv_fel_count, juv_misd_count, priors_count, c_charge_degree, is_violent_recid, v_decile_score, event):\n",
    "  t = torch.as_tensor([sex,age_cat, race, juv_fel_count, juv_misd_count, priors_count, c_charge_degree, is_violent_recid, v_decile_score, event]) \\\n",
    "      .float()\n",
    "  output = net(t)\n",
    "  return output.ge(0.5).item()\n",
    "\n",
    "# Possible values\n",
    "print(\"sex : \" + str(df.sex.unique()))\n",
    "print(\"race : \" + str(df.race.unique()))\n",
    "print(\"age_cat : \" + str(df.age_cat.unique()))\n",
    "print(\"juv_fel_count : \" + str(df.juv_fel_count.unique()))\n",
    "print(\"juv_misd_count : \" + str(df.juv_misd_count.unique()))\n",
    "print(\"priors_count : \" + str(df.priors_count.unique()))\n",
    "print(\"c_charge_degree : \" + str(df.c_charge_degree.unique()))\n",
    "print(\"is_violent_recid : \" + str(df.is_violent_recid.unique()))\n",
    "print(\"v_decile_score : \" + str(df.v_decile_score.unique()))\n",
    "print(\"event : \" + str(df.event.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We want to determine if our model work like Propublica (same, better or worse) by predicting few instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=1, race= 2, age_cat=1, juv_fel_count=2, juv_misd_count=6, priors_count =14, \n",
    "           c_charge_degree =1, is_violent_recid =1, v_decile_score =1, event= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=2, race= 5, age_cat=3, juv_fel_count=1, juv_misd_count=0, priors_count =1, \n",
    "           c_charge_degree =7, is_violent_recid =0, v_decile_score =3, event= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=1, race= 2, age_cat=1, juv_fel_count=0, juv_misd_count=1, priors_count =0, \n",
    "           c_charge_degree =1, is_violent_recid =0, v_decile_score =1, event= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=1, race= 2, age_cat=1, juv_fel_count=2, juv_misd_count=0, priors_count =0, c_charge_degree =1, \n",
    "           is_violent_recid =0, v_decile_score =4, event= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "will_recid(sex=1, race= 5, age_cat=2, juv_fel_count=0, juv_misd_count=2, priors_count =2, c_charge_degree =0, \n",
    "           is_violent_recid =1, v_decile_score =3, event= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Model\n",
    "For subsequent model, we would like to used a validation set. From the dataset, we use 20% of it as the test set and he rest is used for training. We then use 10% of the training set for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>Notes\n",
    "<li>two_year_recid is not possibility. Its the ground truth. What we are trying to do there is to show the ground truth is relatively balanced</li>\n",
    "<li>we could split two times the data, until we have separate: training, testing, and validation set.</li>\n",
    "<li>Maybe its okay to show the figure of the architecture.\n",
    "<li>What is the v_decile_graph for?</li>\n",
    "<li>We can compare by making predictions of some rows in the dataset where the compas classifier failed. For intance maybe there are some rows where score_text is 'High' and decile_score is '10' however the criminals didn't recid (two_year_recid = 0)</li>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\t :torch.Size([5193, 10]), torch.Size([5193])\n",
      "Testing\t\t :torch.Size([1443, 10]), torch.Size([1443])\n",
      "Validation\t :torch.Size([578, 10]), torch.Size([578])\n"
     ]
    }
   ],
   "source": [
    "# Arrange the data : Training, Testing, Validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.1, random_state=RANDOM_SEED)\n",
    "\n",
    "# conversion to tensor\n",
    "X_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n",
    "X_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())\n",
    "X_validate = torch.from_numpy(X_validate.to_numpy()).float()\n",
    "y_validate = torch.squeeze(torch.from_numpy(y_validate.to_numpy()).float())\n",
    "\n",
    "print(\"Training\\t :\"+ str(X_train.shape) +\", \"+ str(y_train.shape))\n",
    "print(\"Testing\\t\\t :\"+ str(X_test.shape) +\", \"+ str(y_test.shape))\n",
    "print(\"Validation\\t :\"+ str(X_validate.shape) +\", \"+ str(y_validate.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Mean Squared Error(MSE)\n",
    "MSE is the default loss function to be used in a regression problem. this is also used when the data is not seperable or for estimation purposes.\n",
    "obviously, this will not perform well on this classification but none the less, we want to see why and how it performs on classification problems.\n",
    "MSE measures the average squared difference between the estimated values and the actual values.\n",
    "With MSE, it is a requirement that the output layer has just one node and also he linear activation function is used in this respect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=5, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "epoch 0\n",
      "            Train set\t\t - loss: 4255.574, accuracy: 0.544\n",
      "            Validation set\t - loss: 467.029, accuracy: 0.548\n",
      "            \n",
      "epoch 400\n",
      "            Train set\t\t - loss: 4255.574, accuracy: 0.544\n",
      "            Validation set\t - loss: 467.029, accuracy: 0.548\n",
      "            \n",
      "epoch 800\n",
      "            Train set\t\t - loss: 4255.574, accuracy: 0.544\n",
      "            Validation set\t - loss: 467.029, accuracy: 0.548\n",
      "            \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.57      1.00      0.73       823\n",
      "       Recid       1.00      0.00      0.00       620\n",
      "\n",
      "    accuracy                           0.57      1443\n",
      "   macro avg       0.79      0.50      0.36      1443\n",
      "weighted avg       0.76      0.57      0.42      1443\n",
      "\n",
      "Overall Accuracy :  0.571032571032571\n"
     ]
    }
   ],
   "source": [
    "#try using different loss function #2\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "#using a nn module from pytorch\n",
    "secondmodel = nn.Sequential(\n",
    "    nn.Linear(10, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1),\n",
    "#     nn.Sigmoid()\n",
    ")\n",
    "print(secondmodel)\n",
    "print(\"\\n\")\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "for epoch in range(1200):\n",
    "    y_pred = secondmodel(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_validate_pred = secondmodel(X_validate)\n",
    "      y_validate_pred = torch.squeeze(y_validate_pred)\n",
    "      validate_loss = criterion(y_validate_pred, y_validate)\n",
    "      validation_acc = calculate_accuracy(y_validate, y_validate_pred)\n",
    "      print(\n",
    "            f'''epoch {epoch}\n",
    "            Train set\\t\\t - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "            Validation set\\t - loss: {round_tensor(validate_loss)}, accuracy: {round_tensor(validation_acc)}\n",
    "            ''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the model using test set\n",
    "y_pred = secondmodel(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model performed poorly using MSE as the loss function. overall accuracy is at 0.64 which is not good to use for predicting if a criminal will recidiviate or not. The accuracy is almost the same as the compass accuacy standing at 0.653.\n",
    "\n",
    "#### Third Model\n",
    "for this model, we would want to see the performance when using tanh activation functions which is non linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thirdmodel(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "epoch 0\n",
      "            Train set\t\t - loss: 1307.027, accuracy: 0.544\n",
      "            Validation set\t - loss: 145.326, accuracy: 0.547\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marck-edward/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400\n",
      "            Train set\t\t - loss: 450.446, accuracy: 0.908\n",
      "            Validation set\t - loss: 54.587, accuracy: 0.9\n",
      "            \n",
      "epoch 800\n",
      "            Train set\t\t - loss: 389.556, accuracy: 0.909\n",
      "            Validation set\t - loss: 47.748, accuracy: 0.901\n",
      "            \n",
      "epoch 1200\n",
      "            Train set\t\t - loss: 382.242, accuracy: 0.91\n",
      "            Validation set\t - loss: 46.838, accuracy: 0.908\n",
      "            \n",
      "epoch 1600\n",
      "            Train set\t\t - loss: 379.303, accuracy: 0.91\n",
      "            Validation set\t - loss: 46.341, accuracy: 0.905\n",
      "            \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.90      0.96      0.93       823\n",
      "       Recid       0.94      0.86      0.90       620\n",
      "\n",
      "    accuracy                           0.91      1443\n",
      "   macro avg       0.92      0.91      0.91      1443\n",
      "weighted avg       0.92      0.91      0.91      1443\n",
      "\n",
      "Overall Accuracy :  0.9147609147609148\n"
     ]
    }
   ],
   "source": [
    "# Using different activation functions : from relu -> tanh\n",
    "class thirdmodel(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features):\n",
    "    super(thirdmodel, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 5)\n",
    "    self.fc2 = nn.Linear(5, 3)\n",
    "    self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.tanh(self.fc1(x))\n",
    "    x = F.tanh(self.fc2(x))\n",
    "    return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "net = thirdmodel(X_train.shape[1])\n",
    "print(net)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "print(\"\\n\")\n",
    "for epoch in range(2000):\n",
    "    y_pred = net(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_validate_pred = net(X_validate)\n",
    "      y_validate_pred = torch.squeeze(y_validate_pred)\n",
    "      validate_loss = criterion(y_validate_pred, y_validate)\n",
    "      validation_acc = calculate_accuracy(y_validate, y_validate_pred)\n",
    "      print(\n",
    "            f'''epoch {epoch}\n",
    "            Train set\\t\\t - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "            Validation set\\t - loss: {round_tensor(validate_loss)}, accuracy: {round_tensor(validation_acc)}\n",
    "            ''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the model using test set\n",
    "y_pred = net(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our third model performs almost same as our first model which had an accuracy of 0.912 and obviously better than the accuracy of compas.\n",
    "### fourth model\n",
    "we build a fourth model by adding more layers to model 2 and more neurons to the hidden layers. Neurons on the input layers has to remain same to fit the shape of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourthmodel(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "epoch 0\n",
      "            Train set\t\t - loss: 1298.756, accuracy: 0.459\n",
      "            Validation set\t - loss: 144.365, accuracy: 0.455\n",
      "            \n",
      "epoch 400\n",
      "            Train set\t\t - loss: 370.967, accuracy: 0.915\n",
      "            Validation set\t - loss: 44.943, accuracy: 0.907\n",
      "            \n",
      "epoch 800\n",
      "            Train set\t\t - loss: 356.537, accuracy: 0.92\n",
      "            Validation set\t - loss: 45.482, accuracy: 0.908\n",
      "            \n",
      "epoch 1200\n",
      "            Train set\t\t - loss: 346.312, accuracy: 0.922\n",
      "            Validation set\t - loss: 45.842, accuracy: 0.908\n",
      "            \n",
      "epoch 1600\n",
      "            Train set\t\t - loss: 339.146, accuracy: 0.926\n",
      "            Validation set\t - loss: 46.408, accuracy: 0.907\n",
      "            \n",
      "epoch 2000\n",
      "            Train set\t\t - loss: 332.674, accuracy: 0.927\n",
      "            Validation set\t - loss: 46.665, accuracy: 0.908\n",
      "            \n",
      "epoch 2400\n",
      "            Train set\t\t - loss: 327.463, accuracy: 0.929\n",
      "            Validation set\t - loss: 47.246, accuracy: 0.908\n",
      "            \n",
      "epoch 2800\n",
      "            Train set\t\t - loss: 323.182, accuracy: 0.931\n",
      "            Validation set\t - loss: 47.661, accuracy: 0.907\n",
      "            \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.90      0.93      0.92       823\n",
      "       Recid       0.91      0.86      0.89       620\n",
      "\n",
      "    accuracy                           0.90      1443\n",
      "   macro avg       0.90      0.90      0.90      1443\n",
      "weighted avg       0.90      0.90      0.90      1443\n",
      "\n",
      "Overall Accuracy :  0.9043659043659044\n"
     ]
    }
   ],
   "source": [
    "# Defining the model  #4\n",
    "# Adding layers and neurons\n",
    "class fourthmodel(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features):\n",
    "    super(fourthmodel, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 20)\n",
    "    self.fc2 = nn.Linear(20, 20)\n",
    "    self.fc3 = nn.Linear(20, 10)\n",
    "    self.fc4 = nn.Linear(10, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.tanh(self.fc1(x))\n",
    "    x = F.tanh(self.fc2(x))\n",
    "    x = F.tanh(self.fc3(x))\n",
    "    return torch.sigmoid(self.fc4(x))\n",
    "\n",
    "net = fourthmodel(X_train.shape[1])\n",
    "print(net)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "print(\"\\n\")\n",
    "for epoch in range(3200):\n",
    "    y_pred = net(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_validate_pred = net(X_validate)\n",
    "      y_validate_pred = torch.squeeze(y_validate_pred)\n",
    "      validate_loss = criterion(y_validate_pred, y_validate)\n",
    "      validation_acc = calculate_accuracy(y_validate, y_validate_pred)\n",
    "      print(\n",
    "            f'''epoch {epoch}\n",
    "            Train set\\t\\t - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "            Validation set\\t - loss: {round_tensor(validate_loss)}, accuracy: {round_tensor(validation_acc)}\n",
    "            ''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the model using test set\n",
    "y_pred = net(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that the accuracy reduced a little by 0.012 as compared to the original third model. We can say that trying to increase the accuracy of the classifier does not have to do with only adding more layers and neurons to the network. We can also observe overfitting starting at epoch 2400.\n",
    "### Fifth model\n",
    "still use the second model but with relu as the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fifthmodel(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "epoch 0\n",
      "            Train set\t\t - loss: 1296.708, accuracy: 0.544\n",
      "            Validation set\t - loss: 144.326, accuracy: 0.547\n",
      "            \n",
      "epoch 400\n",
      "            Train set\t\t - loss: 738.099, accuracy: 0.909\n",
      "            Validation set\t - loss: 84.68, accuracy: 0.894\n",
      "            \n",
      "epoch 800\n",
      "            Train set\t\t - loss: 509.792, accuracy: 0.908\n",
      "            Validation set\t - loss: 59.712, accuracy: 0.898\n",
      "            \n",
      "epoch 1200\n",
      "            Train set\t\t - loss: 451.85, accuracy: 0.91\n",
      "            Validation set\t - loss: 53.745, accuracy: 0.898\n",
      "            \n",
      "epoch 1600\n",
      "            Train set\t\t - loss: 425.465, accuracy: 0.909\n",
      "            Validation set\t - loss: 51.102, accuracy: 0.901\n",
      "            \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Recid       0.89      0.96      0.93       823\n",
      "       Recid       0.95      0.85      0.89       620\n",
      "\n",
      "    accuracy                           0.91      1443\n",
      "   macro avg       0.92      0.90      0.91      1443\n",
      "weighted avg       0.92      0.91      0.91      1443\n",
      "\n",
      "Overall Accuracy :  0.9133749133749134\n"
     ]
    }
   ],
   "source": [
    "# Defining the model #5\n",
    "# Using custom module\n",
    "class fifthmodel(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features):\n",
    "    super(fifthmodel, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 5)\n",
    "    self.fc2 = nn.Linear(5, 3)\n",
    "    self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "net = fifthmodel(X_train.shape[1])\n",
    "print(net)\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "  predicted = y_pred.ge(.5).view(-1)\n",
    "  return (y_true == predicted).sum().float() / len(y_true)\n",
    "\n",
    "def round_tensor(t, decimal_places=3):\n",
    "  return round(t.item(), decimal_places)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "print(\"\\n\")\n",
    "for epoch in range(2000):\n",
    "    y_pred = net(X_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    if epoch % 400 == 0:\n",
    "      train_acc = calculate_accuracy(y_train, y_pred)\n",
    "      y_validate_pred = net(X_validate)\n",
    "      y_validate_pred = torch.squeeze(y_validate_pred)\n",
    "      validate_loss = criterion(y_validate_pred, y_validate)\n",
    "      validation_acc = calculate_accuracy(y_validate, y_validate_pred)\n",
    "      print(\n",
    "            f'''epoch {epoch}\n",
    "            Train set\\t\\t - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "            Validation set\\t - loss: {round_tensor(validate_loss)}, accuracy: {round_tensor(validation_acc)}\n",
    "            ''')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the model using test set\n",
    "y_pred = net(X_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y_test = y_test.cpu()\n",
    "print(classification_report(y_test, y_pred, target_names=classes))\n",
    "print(\"Overall Accuracy : \" , str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an overall accuracy of 0.913 almost same as using tanh as the activation function.\n",
    "\n",
    "Below is a graph showing the difference between the overall accuracies of the five models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "Accuracy = [0.911988911988912, 0.5045045045045045, 0.9147609147609148, 0.896049896049896, 0.911988911988912]\n",
    "Model = ['first_model', 'second Model', 'Third model', 'fourth model', 'fifth model']\n",
    "plt.plot(Model, Accuracy, marker='.', color=\"red\")\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see tha model 1, 3 and 5 performs almost the same.\n",
    "\n",
    "#### Predictions based on fifthmodel\n",
    "\n",
    "we want to define a new dataset to use for prediction and oserve fairness. We will use criminals labelled with the various risk score/decile score but having a two_year_recid or for this analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data is  (402, 10)\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "         True, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "         True, False, False, False, False, False, False,  True,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False,  True, False,  True,  True,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "         True, False, False, False, False,  True, False, False, False, False,\n",
      "         True,  True, False,  True, False, False, False,  True, False, False,\n",
      "        False,  True,  True, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "         True, False, False, False, False,  True, False, False, False, False,\n",
      "        False,  True, False, False, False, False,  True, False, False, False,\n",
      "         True, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False,  True,  True,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False,  True,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False,  True,  True, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False,  True, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False,  True, False,  True, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "#no two_year _recid with high label\n",
    "df2 = df2.loc[(df2['two_year_recid']==0) & (df2['score_text']=='High')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df3 = df2[df.columns[~df.isnull().any()]]\n",
    "df3 = df3[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "\n",
    "print ('shape of data is ', df3.shape)\n",
    "\n",
    "#prediction\n",
    "X_pred = torch.from_numpy(df3.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data is  (1001, 10)\n",
      "tensor([True, True, True,  ..., True, True, True])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "#no two_year _recid with high label\n",
    "df2 = df2.loc[(df2['two_year_recid']==1) & (df2['score_text']=='High')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df3 = df2[df.columns[~df.isnull().any()]]\n",
    "df3 = df3[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "\n",
    "print ('shape of data is ', df3.shape)\n",
    "\n",
    "#prediction\n",
    "X_pred = torch.from_numpy(df3.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of is  (1216, 10)\n",
      "tensor([ True, False,  True,  ...,  True,  True, False])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#two_year _recid with Low label\n",
    "df2 = df2.loc[(df2['two_year_recid']==1) & (df2['score_text']=='Low')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of is ', df2.shape)\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of is  (1001, 10)\n",
      "tensor([True, True, True,  ..., True, True, True])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#two_year _recid with high label\n",
    "df2 = df2.loc[(df2['two_year_recid']==1) & (df2['score_text']=='High')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of is ', df2.shape)\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of is  (880, 10)\n",
      "tensor([ True, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "         True, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "         True,  True, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False,  True, False,  True,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False,  True, False, False,  True, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "         True, False, False,  True, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False,  True,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False, False, False,\n",
      "         True, False, False, False,  True, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False,  True, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False,  True, False, False, False, False,  True, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False,  True,  True, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False,  True, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False,  True,  True, False,  True, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#no two_year _recid with Medium label\n",
    "df2 = df2.loc[(df2['two_year_recid']==0) & (df2['score_text']=='Medium')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of is ', df2.shape)\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of is  (402, 10)\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True,  True, False, False, False, False, False,\n",
      "        False, False,  True, False,  True, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True, False, False, False, False, False, False,  True,  True, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False,  True, False, False, False, False,  True, False, False,\n",
      "         True,  True,  True, False, False, False, False,  True, False, False,\n",
      "        False, False, False,  True,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False,  True,  True, False, False, False, False,  True, False, False,\n",
      "        False,  True,  True, False, False, False, False, False,  True,  True,\n",
      "         True,  True, False, False, False, False, False, False,  True, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False, False, False, False,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "         True, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False,  True, False, False, False, False,  True,  True, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False,  True,  True, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False,  True,  True, False, False,\n",
      "        False,  True, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "         True, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False])\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('compas-scores-two-years.csv')\n",
    "\n",
    "#no two_year _recid with high label\n",
    "df2 = df2.loc[(df2['two_year_recid']==0) & (df2['score_text']=='High')]\n",
    "# print ('shape of filtered data is ', df2.shape)\n",
    "\n",
    "df2 = df2[df.columns[~df.isnull().any()]]\n",
    "df2 = df2[['sex','age_cat', 'race', 'juv_fel_count', 'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "         'is_violent_recid', 'v_decile_score', 'event', ]]\n",
    "df2['sex'].replace({'Male': 1, 'Female': 2}, inplace = True)\n",
    "df2['age_cat'].replace({'Greater than 45': 1, '25 - 45': 2, 'Less than 25': 3}, inplace = True)\n",
    "df2['race'].replace({'Other': 1, 'African-American': 2, 'Caucasian': 3, 'Hispanic': 4, 'Native American': 5, 'Asian': 6}, inplace = True)\n",
    "df2['c_charge_degree'].replace({'F': 1, 'M': 2}, inplace = True)\n",
    "\n",
    "print ('shape of is ', df2.shape)\n",
    "X_pred = torch.from_numpy(df2.to_numpy()).float()\n",
    "X_pred = net(X_pred)\n",
    "X_pred = X_pred.ge(.5).view(-1).cpu()\n",
    "print (X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
